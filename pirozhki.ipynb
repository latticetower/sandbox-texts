{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача: есть 2 набора стихов-\"пирожков\", которые мы хотим научиться отличать друг от друга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    buf = []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            l = line.strip()\n",
    "            if len(l) > 0:\n",
    "                buf.append(l)\n",
    "            else:\n",
    "                if len(buf) > 0:\n",
    "                    yield buf\n",
    "                    buf = []\n",
    "        if len(buf) > 0:\n",
    "            yield buf\n",
    "\n",
    "class0 = list(read_data(\"test_data/class0.txt\"))\n",
    "class1 =  list(read_data(\"test_data/class1.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как выглядят данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ребята мне совсем хреново',\n",
       "  'друзьям аркадий говорит',\n",
       "  'друзья качают головами',\n",
       "  'и тычут палочкой в нево'],\n",
       " ['придя домой семён наткнулся',\n",
       "  'на лужу серной кислоты',\n",
       "  'скорее вытирать скорее',\n",
       "  'пока к соседям не прожгло']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class0[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['дантес сойду еще не речи',\n",
       "  'потенциен от укла нет',\n",
       "  'была ушли в уборной шляпе',\n",
       "  'высоковольтный педикюр',\n",
       "  'быстрят особенное снежно',\n",
       "  'с вилкой уже сказал блины'],\n",
       " ['я понял то что не увозит',\n",
       "  'и чо опасниками день',\n",
       "  'а он настроит рыбин к людек',\n",
       "  'а над оконною женой',\n",
       "  'что ж кто мечтательно подходит',\n",
       "  'и был любимой словно тонн']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class1[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И там, и там стихи многострочные. Обычно пирожки содержат 4 строки. Мы можем посмотреть, сколькистрочные стихи содержат оба класса и выкинуть то, что 4 строки не содержит - по определению, это не \"пирожок\".\n",
    "Проверим количество строк в классах:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проверка количества строк в пирожках\n",
      "Класс 0: Counter({4: 1095})\n",
      "Класс 1: Counter({4: 785, 2: 110, 6: 87, 8: 19, 3: 4, 10: 3, 1: 3, 14: 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(\"Проверка количества строк в пирожках\")\n",
    "print(\"Класс 0: %s\" % Counter(map(len, class0)))\n",
    "print(\"Класс 1: %s\" % Counter(map(len, class1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В классе 1 есть довольно много стихов не из 4 строк. Уберем их из рассмотрения и случайным образом продублируем стихи из класса 1, чтобы сбалансировать количество стихов в каждом из классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1095, 1095, Counter({4: 1095}), Counter({4: 1095}))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class1 = list(filter(lambda x: len(x)==4, class1))\n",
    "\n",
    "class1 += list(\n",
    "    map(lambda i: class1[i], \n",
    "        np.random.randint(0, len(class1), size=len(class0)-len(class1))))\n",
    "\n",
    "len(class0), len(class1), Counter(list(map(len, class0))), Counter(list(map(len, class1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Теперь все хорошо. Выделим обучающую и тестовую выборки, чтобы дальше работать с ними."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = list(map(lambda x:\"\\n\".join(x), class0 + class1))\n",
    "y_data = np.concatenate((np.zeros(len(class0)),np.ones(len(class1))), axis=0)  \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, stratify=y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Общие выводы\n",
    "\n",
    "Пирожки из класса 1 пытаются мимикрировать под пирожки из класса 0, в которых часто есть ошибки и опечатки. Для класса 1 характерны не естественные для человека опечатки, новые слова, не связанность текста. Каждое стихотворение из класса 0 семантически согласовано - все строки связаны либо по смыслу, либо грамматически. Человек не будет употреблять глагол вместо прилагательного. В классе 1 такие примеры есть и они бросаются в глаза. \n",
    "\n",
    "Можно сравнить:\n",
    "\n",
    "1. структуру текста (в том числе используя представление о структуре пирожков)\n",
    "\n",
    "2. используя какую-либо метрику, например, расстояние Левенштейна, определять опечатки. Пытаться определить смысл оригинальных слов и посмотреть, насколько это будет влиять на точность определения структуры текста.\n",
    "\n",
    "3. определить основные части речи (существительное, глагол) в тексте и сравнить, насколько они употребимы вместе друг с другом.\n",
    "\n",
    "4. посмотреть прилагательные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a. bag-of-words (простой)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "count_vectorizer = CountVectorizer().fit(x_train)\n",
    "\n",
    "x_train_vect = count_vectorizer.transform(x_train)\n",
    "x_test_vect = count_vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший score на обучающей выборке:  0.654689403167\n",
      "Score лучшей модели на тестовой выборке: 0.655109489051\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "lr = LogisticRegression()\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "grid = GridSearchCV(lr, param_grid, cv=10)\n",
    "grid.fit(x_train_vect, y_train)\n",
    "print(\"Лучший score на обучающей выборке: \", grid.best_score_)\n",
    "\n",
    "print(\"Score лучшей модели на тестовой выборке:\", \n",
    "      np.mean(\n",
    "          np.equal(\n",
    "              grid.best_estimator_.predict(x_test_vect), \n",
    "              y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем использовать TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший score на обучающей выборке:  0.601096224117\n",
      "Score лучшей модели на тестовой выборке 0.569343065693\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(TfidfVectorizer(min_df=5, norm=None), LogisticRegression())\n",
    "param_grid = {'logisticregression__C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "grid = GridSearchCV(pipe, param_grid, cv=10)\n",
    "grid.fit(x_train, y_train)\n",
    "print(\"Лучший score на обучающей выборке: \", grid.best_score_)\n",
    "print(\"Score лучшей модели на тестовой выборке\",\n",
    "      np.mean(\n",
    "          np.equal(\n",
    "              grid.best_estimator_.predict(x_test), \n",
    "              y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score на обучающей выборке:  1.0\n",
      "Score на тестовой выборке: 0.647810218978\n"
     ]
    }
   ],
   "source": [
    "# ну и дерево - для сравнения\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier().fit(x_train_vect, y_train)\n",
    "print(\"Score на обучающей выборке: \", np.mean(\n",
    "          np.equal(\n",
    "              dt.predict(x_train_vect), \n",
    "              y_train)))\n",
    "\n",
    "print(\"Score на тестовой выборке:\", \n",
    "      np.mean(\n",
    "          np.equal(\n",
    "              dt.predict(x_test_vect), \n",
    "              y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Вывод: bag of words без доп.обработки текстов дает не очень хороший результат. Это может быть связано с тем, что в обоих классах присутствуют несловарные слова (слова с опечатками), в классе 0 - имена собственные (Путин, Куклачев и др.), много уникальных слов (дерево отличает чуть лучше - видимо, дело в том, что все-таки эти несловарные слова позволяют отличать класс 1 от класса 0 чуть лучше, хотя и ненамного)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b.  bag-of-words с предобработкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import nltk \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "ru_stopwords = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Попробуем добавить простой метод для разбивки пирожков на слова, который будет приводить их к нормальной форме и сравним score логистической регрессии для разных вариантов обработки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['а', 'роза', 'упасть', 'на', 'лапа', 'азор']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_custom_tokenizer(stopwords={}):\n",
    "    def _custom_tokenizer(s):\n",
    "        xs = s.split()\n",
    "        return list(filter(lambda x: x not in stopwords,\n",
    "                      map(lambda word: morph.parse(word)[0].normal_form, xs)))\n",
    "    return _custom_tokenizer\n",
    "\n",
    "custom_tokenizer = make_custom_tokenizer()\n",
    "custom_tokenizer(\"А роза упала на лапу Азора\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "custom_tokenizer2 = make_custom_tokenizer(ru_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score на обучающей выборке без выкидывания стоп-слов 0.63394798707\n",
      "С выкидыванием стоп-слов 0.629672347928\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "x_train_vect = CountVectorizer(\n",
    "        max_features=10000, \n",
    "        max_df=.15, \n",
    "        tokenizer=custom_tokenizer\n",
    "    ).fit(x_train).transform(x_train)\n",
    "\n",
    "scores = cross_val_score(LogisticRegression(), x_train_vect, y_train, cv=10)\n",
    "print(\"Score на обучающей выборке без выкидывания стоп-слов\", np.mean(scores))\n",
    "\n",
    "\n",
    "vect = CountVectorizer(\n",
    "        max_features=10000, \n",
    "        max_df=.15, \n",
    "        tokenizer=custom_tokenizer2\n",
    "    ).fit(x_train)\n",
    "x_train_vect = vect.transform(x_train)\n",
    "\n",
    "scores = cross_val_score(LogisticRegression(), x_train_vect, y_train, cv=10)\n",
    "print(\"С выкидыванием стоп-слов\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2. Простая модель с word2vec и здравым смыслом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Если посмотреть на данные обоих классов, то заметны следующие отличия:\n",
    "\n",
    "1. В классе 0 слова в отдельных строках связаны между собой, в классе 1 часто не связаны никак\n",
    "2. В классе 1 встречаются несогласованные по родам и временам пары \"прилагательное-существительное\", \"существительное-глагол\", в то время как в классе 0 их нет (вероятно, потому, что как правило, человек такие ошибки не допускает)\n",
    "\n",
    "Можно попробовать: \n",
    "1. взять обученную word2vec-модель, с ее помощью попарно сравнить строки, найти в них пары наиболее похожих слов, соответствующие числовые характеристики использовать в качестве признаков.\n",
    "2. добавить булевые признаки - наличие несоответствий в строках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "keyed_vect = KeyedVectors.load_word2vec_format(\"ruscorpora_1_300_10.bin.gz\", binary=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'двойка_NOUN'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# в ruscorpora используется отличный от pymorphy2 формат POS-тэгов, слова в модели идут уже с ними.\n",
    "# Следующий метод получает нужный тег и приписывает его к слову, сохраняя его оригинальную форму.\n",
    "def preprocess_word(x):\n",
    "    forms = morph.parse(x)\n",
    "    for m in forms:\n",
    "        if m.tag.POS is None:\n",
    "            #print(x, m.tag.POS)\n",
    "            continue\n",
    "        if m.tag.POS.startswith('ADJ'):\n",
    "            return m.normal_form + \"_ADJ\"\n",
    "        if m.tag.POS =='INFN':\n",
    "            return m.normal_form + \"_VERB\"\n",
    "        if m.tag.POS == 'NPRO':\n",
    "            return m.normal_form + \"_PRON\"\n",
    "        return m.normal_form + \"_\" + m.tag.POS\n",
    "    return x + \"_UNKNOWN\"\n",
    "\n",
    "preprocess_word(\"двойка\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('роза_NOUN', 'зоря_NOUN', 0.24094977034332399)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_similarity(line1, line2):\n",
    "    line1 = [preprocess_word(x) for x in line1.split() if not x in ru_stopwords]\n",
    "    line2 = [preprocess_word(x) for x in line2.split() if not x in ru_stopwords]\n",
    "    m = 0\n",
    "    i0=-1\n",
    "    j0=-1\n",
    "    for i in line1:\n",
    "        for j in line2:\n",
    "            if not i.split('_')[1] in set(['NOUN', 'VERB', 'ADJ', 'PRON']):\n",
    "                continue\n",
    "            if not j.split('_')[1] in set(['NOUN', 'VERB', 'ADJ','PRON']):\n",
    "                continue\n",
    "            if not i in keyed_vect.vocab:\n",
    "                i1 = morph.parse(i.split(\"_\")[0])[0]\n",
    "                j1 = morph.parse(j.split(\"_\")[0])[0]\n",
    "                if i1.normal_form == j1.normal_form:\n",
    "                    return i, j, 1.0\n",
    "                continue\n",
    "            if not j in keyed_vect.vocab:\n",
    "                i1 = morph.parse(i.split(\"_\")[0])[0]\n",
    "                j1 = morph.parse(j.split(\"_\")[0])[0]\n",
    "                if i1.normal_form == j1.normal_form:\n",
    "                    return i, j, 1.0\n",
    "                continue\n",
    "            if keyed_vect.similarity(i, j) > m:\n",
    "                m=keyed_vect.similarity(i, j)\n",
    "                i0=i\n",
    "                j0=j\n",
    "    return i0, j0, m\n",
    "\n",
    "\n",
    "get_similarity(\"а роза упала на лапу азора\", \"а зори здесь тихие\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def preprocess_poem(poem):\n",
    "    if isinstance(poem, str):\n",
    "        poem = poem.split('\\n')\n",
    "    for i in range(4):\n",
    "        for j in range(i + 1,4):\n",
    "            yield i, j, get_similarity(poem[i], poem[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ребята мне совсем хреново\n",
      "друзьям аркадий говорит\n",
      "друзья качают головами\n",
      "и тычут палочкой в нево\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([(0, 1, ('ребята_NOUN', 'друг_NOUN', 0.3061908933626224)),\n",
       "  (0, 2, ('ребята_NOUN', 'друг_NOUN', 0.3061908933626224)),\n",
       "  (0, 3, ('ребята_NOUN', 'тыкать_VERB', 0.24149795902845334)),\n",
       "  (1, 2, ('друг_NOUN', 'друг_NOUN', 1.0000000000000004)),\n",
       "  (1, 3, ('говорить_VERB', 'тыкать_VERB', 0.33467823884290354)),\n",
       "  (2, 3, ('качать_VERB', 'тыкать_VERB', 0.37435990903307714))],\n",
       " None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(preprocess_poem(x_data[0])), print(x_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# добавляет попарные значения похожести в качестве признаков, а также, отдельным признаком - \n",
    "# максимальное значение похожести среди всех пар строк\n",
    "def processed_to_features(xs):\n",
    "    x = [np.concatenate((np.asarray([k[-1] for i, j, k in (preprocess_poem(x))\n",
    "                    ]).T, np.asarray([\n",
    "        max(map(lambda x: x[2][-1], preprocess_poem(x)))]))) for x in xs]\n",
    "    return np.vstack(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "custom_features = processed_to_features(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1642, 7)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def check_line(line):\n",
    "    \"проверяет строку на наличие проблем согласования родов\"\n",
    "    xs = [x for x in line.split()]\n",
    "    for i in range(len(xs)-1):\n",
    "        x1 = morph.parse(xs[i])[0]\n",
    "        x2 = morph.parse(xs[i + 1])[0]\n",
    "        if x1.tag.POS is None:\n",
    "            continue\n",
    "        if x2.tag.POS is None:\n",
    "            continue\n",
    "        for x1, x2 in [(x1, x2), (x2, x1)]:\n",
    "            if x1.tag.POS.startswith('ADJF') and x2.tag.POS=='NOUN':\n",
    "                if x1.tag.number != x2.tag.number or x1.tag.gender != x2.tag.gender:\n",
    "                    #print(x1, x2)\n",
    "                    return True\n",
    "        if x1.tag.POS.startswith('NOUN') and x2.tag.POS=='VERB':\n",
    "            if x1.tag.number != x2.tag.number or (x1.tag.gender != x2.tag.gender and \"impf\" not in x2.tag):\n",
    "                #print(x1, x2)\n",
    "                return True\n",
    "    return False\n",
    "                \n",
    "def check_pairs(poem):\n",
    "    \"\"\"This tries to check nouns in lines and returns true/false values (or counts?) based on \n",
    "    how many cases there were with incorrect part of speech\n",
    "    \"\"\"\n",
    "    x = [check_line(line) for line in poem.split('\\n')] \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "check_line('а зеленая роза упал на лапу азора')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "boolean_features = np.vstack([np.asarray(check_pairs(x)) for x in x_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_features = np.concatenate((custom_features, boolean_features), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.27090745,  0.30467402,  0.28084496, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.35168789,  0.        ,  0.08408675, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.34805499,  0.22577519,  0.4770446 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ..., \n",
       "       [ 0.16354329,  0.23429986,  0.27524324, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.32957714,  0.5960909 ,  0.26527108, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.20761791,  0.        ,  0.28771346, ...,  1.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средний score кросс-валидации на обучающей выборке 0.737525712607\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(LogisticRegression(), X_features, y_train, cv=10)\n",
    "print(\"Средний score кросс-валидации на обучающей выборке\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "custom_features = processed_to_features(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boolean_features = np.vstack([np.asarray(check_pairs(x)) for x in x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_features_test = np.concatenate((custom_features, boolean_features), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score логистической регрессии на тестовой выборке 0.724452554745\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression().fit(X_features, y_train)\n",
    "print(\"Score логистической регрессии на тестовой выборке\", \n",
    "      np.mean(np.equal(lr.predict(X_features_test), y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Выводы\n",
    "Как видим, даже совсем простой анализ текста приводит к небольшому, но заметному улучшению результата по сравнению с bag-of-words."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "source": [
    "# Код с LDA закомментирован, т.к. на наборе коротких текстов темы получаются малоосмысленные\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_topics=100, \n",
    "                                learning_method=\"batch\", max_iter=25, random_state=0)\n",
    "lda10 = lda.fit(x_train_vect).transform(x_train_vect)\n",
    "sorting = np.argsort(lda.components_, axis=1)[:, ::-1]\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "for x in range(100):\n",
    "    print(x, \", \".join([feature_names[sorting[x, j]] for j in range(20) ]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
